## 进入到自己的工作路径: cd /data/03_Metagenomics/你的名字
# 1.1 低质量碱基过滤
mkdir -p 01.QC/01-trim
trimmomatic PE /db/metagenome/rawfq/S1.R1.fq.gz /db/metagenome/rawfq/S1.R2.fq.gz \
01.QC/01-trim/S1.pe.R1.fastq 01.QC/01-trim/S1.unpe.R1.fastq \
01.QC/01-trim/S1.pe.R2.fastq 01.QC/01-trim/S1.unpe.R2.fastq \
LEADING:3 TRAILING:3 SLIDINGWINDOW:5:20 MINLEN:50 \
-phred33 ILLUMINACLIP:/db/metagenome/rawfq/TruSeq3-PE.fa:2:30:10

trimmomatic PE /db/metagenome/rawfq/S2.R1.fq.gz /db/metagenome/rawfq/S2.R2.fq.gz \
01.QC/01-trim/S2.pe.R1.fastq 01.QC/01-trim/S2.unpe.R1.fastq \
01.QC/01-trim/S2.pe.R2.fastq 01.QC/01-trim/S2.unpe.R2.fastq \
LEADING:3 TRAILING:3 SLIDINGWINDOW:5:20 MINLEN:50 \
-phred33 ILLUMINACLIP:/db/metagenome/rawfq/TruSeq3-PE.fa:2:30:10
# 1.2 去除PCR重复
mkdir -p 01.QC/02-uniq
realpath 01.QC/01-trim/S1.pe* > 01.QC/02-uniq/S1.input.fastuniq
realpath 01.QC/01-trim/S2.pe* > 01.QC/02-uniq/S2.input.fastuniq

fastuniq -i 01.QC/02-uniq/S1.input.fastuniq -t q \
-o 01.QC/02-uniq/S1.uniq.R1.fq \
-p 01.QC/02-uniq/S1.uniq.R2.fq \
-c 0

fastuniq -i 01.QC/02-uniq/S2.input.fastuniq -t q \
-o 01.QC/02-uniq/S2.uniq.R1.fq \
-p 01.QC/02-uniq/S2.uniq.R2.fq \
-c 0

# 1.3 去宿主
mkdir -p 01.QC/03-rmhost
bwa mem -k 30 /db/metagenome/hg38/GRCh38_latest_genomic.fna 01.QC/02-uniq/S2.uniq.R1.fq 01.QC/02-uniq/S2.uniq.R2.fq >  01.QC/03-rmhost/S2.sam

bwa mem -k 30 /db/metagenome/hg38/GRCh38_latest_genomic.fna 01.QC/02-uniq/S1.uniq.R1.fq 01.QC/02-uniq/S1.uniq.R2.fq > 01.QC/03-rmhost/S1.sam

awk -F '\t' '$3=="*"{print $1}' 01.QC/03-rmhost/S1.sam|sort|uniq|seqtk subseq 01.QC/02-uniq/S1.uniq.R1.fq - > 01.QC/03-rmhost/S1.nohost.R1.fq

awk -F '\t' '$3=="*"{print $1}' 01.QC/03-rmhost/S1.sam|sort|uniq|seqtk subseq 01.QC/02-uniq/S1.uniq.R2.fq - > 01.QC/03-rmhost/S1.nohost.R2.fq

awk -F '\t' '$3=="*"{print $1}' 01.QC/03-rmhost/S2.sam|sort|uniq|seqtk subseq 01.QC/02-uniq/S2.uniq.R1.fq - > 01.QC/03-rmhost/S2.nohost.R1.fq

awk -F '\t' '$3=="*"{print $1}' 01.QC/03-rmhost/S2.sam|sort|uniq|seqtk subseq 01.QC/02-uniq/S2.uniq.R2.fq - > 01.QC/03-rmhost/S2.nohost.R2.fq



# 1.4 序列与碱基数量统计
mkdir -p 01.QC/04-count
fqBaseSum 01.QC/03-rmhost/S1.nohost.R1.fq > 01.QC/04-count/fq.stat.txt
fqBaseSum 01.QC/03-rmhost/S1.nohost.R2.fq >> 01.QC/04-count/fq.stat.txt
fqBaseSum 01.QC/03-rmhost/S2.nohost.R1.fq >> 01.QC/04-count/fq.stat.txt
fqBaseSum 01.QC/03-rmhost/S2.nohost.R2.fq >> 01.QC/04-count/fq.stat.txt

# 1.5 fastqc 质量报告
mkdir -p 01.QC/05-report/S1.fastqc.out
mkdir -p 01.QC/05-report/S2.fastqc.out
fastqc -o 01.QC/05-report/S1.fastqc.out 01.QC/02-uniq/S1.uniq.R1.fq 01.QC/02-uniq/S1.uniq.R2.fq
fastqc -o 01.QC/05-report/S2.fastqc.out 01.QC/02-uniq/S2.uniq.R1.fq 01.QC/02-uniq/S2.uniq.R2.fq


# 2.1 megahit 组装
mkdir -p 02.Assembly/01-sample
megahit -t 1 -1 01.QC/02-uniq/S1.uniq.R1.fq -2 01.QC/02-uniq/S1.uniq.R2.fq \
--out-dir 02.Assembly/01-sample/S1.assembly \
--k-min 35 --k-max 95 --k-step 20 --min-contig-len 500

megahit -t 1 -1 01.QC/02-uniq/S2.uniq.R1.fq -2 01.QC/02-uniq/S2.uniq.R2.fq \
--out-dir 02.Assembly/01-sample/S2.assembly \
--k-min 35 --k-max 95 --k-step 20 --min-contig-len 500

# 2.2 样品中未利用的reads 进行混合组装
mkdir -p 02.Assembly/02-unmap
bwa index 02.Assembly/01-sample/S1.assembly/final.contigs.fa
bwa index 02.Assembly/01-sample/S2.assembly/final.contigs.fa

bwa mem -k 19 02.Assembly/01-sample/S1.assembly/final.contigs.fa \
01.QC/02-uniq/S1.uniq.R1.fq 01.QC/02-uniq/S1.uniq.R2.fq > 02.Assembly/02-unmap/S1.unused.sam

bwa mem -k 19 02.Assembly/01-sample/S2.assembly/final.contigs.fa \
01.QC/02-uniq/S2.uniq.R1.fq 01.QC/02-uniq/S2.uniq.R2.fq > 02.Assembly/02-unmap/S2.unused.sam

awk -F '\t' '$3=="*"{print $1}' 02.Assembly/02-unmap/S1.unused.sam|sort|uniq| \
seqtk subseq 01.QC/02-uniq/S1.uniq.R1.fq - > 02.Assembly/02-unmap/S1.unmap.R1.fq
awk -F '\t' '$3=="*"{print $1}' 02.Assembly/02-unmap/S1.unused.sam|sort|uniq| \
seqtk subseq 01.QC/02-uniq/S1.uniq.R2.fq - > 02.Assembly/02-unmap/S1.unmap.R2.fq

awk -F '\t' '$3=="*"{print $1}' 02.Assembly/02-unmap/S2.unused.sam|sort|uniq| \
seqtk subseq 01.QC/02-uniq/S2.uniq.R1.fq - > 02.Assembly/02-unmap/S2.unmap.R1.fq
awk -F '\t' '$3=="*"{print $1}' 02.Assembly/02-unmap/S2.unused.sam|sort|uniq| \
seqtk subseq 01.QC/02-uniq/S2.uniq.R2.fq - > 02.Assembly/02-unmap/S2.unmap.R2.fq

megahit -1 02.Assembly/02-unmap/S1.unmap.R1.fq,02.Assembly/02-unmap/S2.unmap.R1.fq \
-2 02.Assembly/02-unmap/S1.unmap.R2.fq,02.Assembly/02-unmap/S2.unmap.R2.fq \
--out-dir 02.Assembly/02-unmap/unmap.assembly \
--k-min 35 --k-max 95 --k-step 20 --min-contig-len 500

# 2.3 组装结果统计
mkdir -p 02.Assembly/03-stat
pileup.sh in=02.Assembly/02-unmap/S1.unused.sam \
ref=02.Assembly/01-sample/S1.assembly/final.contigs.fa \
out=02.Assembly/03-stat/S1.covstats.txt overwrite=true

pileup.sh in=02.Assembly/02-unmap/S2.unused.sam \
ref=02.Assembly/01-sample/S2.assembly/final.contigs.fa \
out=02.Assembly/03-stat/S2.covstats.txt overwrite=true

#3.1 orf 预测
mkdir -p 03.Predict/01-orf
prodigal -i 02.Assembly/01-sample/S1.assembly/final.contigs.fa \
-o 03.Predict/01-orf/S1.gene.gff \
-a 03.Predict/01-orf/S1.gene.faa \
-d 03.Predict/01-orf/S1.gene.ffn \
-f gff -g 11 -p meta

prodigal -i 02.Assembly/01-sample/S2.assembly/final.contigs.fa \
-o 03.Predict/01-orf/S2.gene.gff \
-a 03.Predict/01-orf/S2.gene.faa \
-d 03.Predict/01-orf/S2.gene.ffn \
-f gff -g 11 -p meta

# 3.3 Antifam 数据库
mkdir -p 03.Predict/03-psudogene
hmmsearch --domtblout 03.Predict/03-psudogene/S1.antifam.out \
--domE 1e-10 \
/db/metagenome/antifam/AntiFam.hmm \
03.Predict/01-orf/S1.gene.faa

hmmsearch --domtblout 03.Predict/03-psudogene/S2.antifam.out \
--domE 1e-10 \
/db/metagenome/antifam/AntiFam.hmm \
03.Predict/01-orf/S2.gene.faa

# 3.4 基因聚类
mkdir -p 03.Predict/04-clust
cat 03.Predict/01-orf/*.ffn > 03.Predict/04-clust/all.gene.ffn.tmp
awk '{if ($1~">") {
    n+=1
    print ">Unigene"n
  } else {
    print
  }
}' 03.Predict/04-clust/all.gene.ffn.tmp > \
03.Predict/04-clust/all.gene.ffn
mmseqs createdb 03.Predict/04-clust/all.gene.ffn 03.Predict/04-clust/DB
mmseqs linclust 03.Predict/04-clust/DB \
03.Predict/04-clust/DB_clu \
03.Predict/04-clust/tmp \
-k 0 -e 0.001 --min-seq-id 0.95 -c 0.9 --cluster-mode 0

mmseqs createsubdb 03.Predict/04-clust/DB_clu \
03.Predict/04-clust/DB \
03.Predict/04-clust/DB_clu_rep

mmseqs convert2fasta 03.Predict/04-clust/DB_clu_rep \
03.Predict/04-clust/DB_clu_rep.fasta

mmseqs createtsv 03.Predict/04-clust/DB 03.Predict/04-clust/DB_clu 03.Predict/04-clust/query_linclust_cluster.tsv

# 3.5 比对定量
mkdir -p 03.Predict/05-abundance
mv 03.Predict/04-clust/DB_clu_rep.fasta 03.Predict/04-clust/gene_catalogue.ffn

bwa index 03.Predict/04-clust/gene_catalogue.ffn

bwa mem -k 19 03.Predict/04-clust/gene_catalogue.ffn \
01.QC/02-uniq/S1.uniq.R1.fq 01.QC/02-uniq/S1.uniq.R2.fq > \
03.Predict/05-abundance/S1.sam

bwa mem -k 19 03.Predict/04-clust/gene_catalogue.ffn \
01.QC/02-uniq/S2.uniq.R1.fq 01.QC/02-uniq/S2.uniq.R2.fq > \
03.Predict/05-abundance/S2.sam

pileup.sh in=03.Predict/05-abundance/S1.sam \
ref=03.Predict/04-clust/gene_catalogue.ffn \
out=03.Predict/05-abundance/S1.covstats.txt overwrite=true

pileup.sh in=03.Predict/05-abundance/S2.sam \
ref=03.Predict/04-clust/gene_catalogue.ffn \
out=03.Predict/05-abundance/S2.covstats.txt overwrite=true

# 4.1 基于reads的注释
mkdir -p 04.Annotation/01-metaphlan
metaphlan  01.QC/02-uniq/S1.uniq.R1.fq,01.QC/02-uniq/S1.uniq.R2.fq \
--bowtie2out 04.Annotation/01-metaphlan/S1.bowtie2.bz2 \
--input_type fastq \
-o 04.Annotation/01-metaphlan/S1.taxa.profile.txt

metaphlan  01.QC/02-uniq/S2.uniq.R1.fq,01.QC/02-uniq/S2.uniq.R2.fq \
--bowtie2out 04.Annotation/01-metaphlan/S2.bowtie2.bz2 \
--input_type fastq \
-o 04.Annotation/01-metaphlan/S2.taxa.profile.txt

## human注释
mkdir -p 04.Annotation/02-humann
humann --input /db/metagenome/SRR8675901.1.fastq --output 04.Annotation/02-humann
humann_regroup_table --input 04.Annotation/02-humann/SRR8675901.1_genefamilies.tsv --groups uniref50 --output uniref50_ko
humann_renorm_table --input 04.Annotation/02-humann/SRR8675901.1_genefamilies.tsv --output 04.Annotation/02-humann/SRR8675901.1_relab.tsv --units relab --special n